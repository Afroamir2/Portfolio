---
title: "ANN for Catchment"
author: "F410310"
date: "2025-03-22"
output:
  pdf_document:
    includes:
      in_header: header.tex
  word_document: default
header-includes:
- \usepackage{booktabs}
- \usepackage{graphicx}
- \usepackage{multirow}
---

\clearpage


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
setwd("~/repos/Portfolio/ANN")
library(reticulate)
reticulate::use_python("/Users/amirousanoussy/Application/anaconda3/bin/python", required = TRUE)
reticulate::py_config()



```

```{python}

import pandas as pd
import numpy as np
import matplotlib.pylab as plt
from scipy.stats.mstats import winsorize
from sklearn.preprocessing import MinMaxScaler
import time
from sklearn.model_selection import train_test_split
import random
```
# Introduction & Set Up 

I implemented the neural network using Python due to its robust ecosystem for data science and machine learning. Python was chosen for its readability, ease of prototyping, and the availability of libraries that simplify tasks such as data manipulation, numerical computation, and visualization. In this project, I utilized libraries such as NumPy for numerical operations, pandas for handling and reformatting the multi-indexed time series data, matplotlib for generating visualizations, and sci-kit-learn for preprocessing tasks like applying MinMax scaling and splitting the dataset.


# Data Pre-processing


During the data pre-processing stage, I examined the dataset’s dimensions, which consisted of 12 columns and 1462 rows. Further inspection revealed that the data was a multi-indexed time series. However, when initially imported from an Excel file, the multi-index was not properly configured, the columns were misplaced, the time index was not correctly set up, and the data types for both the columns and the index were not appropriately defined. As such, the first step was to restructure and reformat the dataset, ensuring that the multi-index, time indexing, and data types were properly established to facilitate efficient further analysis. Which can be seen in the following code chunks


```{python, results='asis'}


# Read the Excel file and select the sheet named "1993-96"
df = pd.read_excel("Ouse93-96 - Student.xlsx", sheet_name="1993-96")
```

```{python, echo=FALSE, results='asis'}

table_str = "\\resizebox{\\textwidth}{!}{\n" + df.head().to_latex(index=True, escape=True) + "\n}"
print(table_str)
```

## Data Reformatting 
```{python, results='asis', tidy=TRUE, tidy.opts=list(width.cutoff=60)}
# Extract the first column (assumed to contain date information) for later use
data_series = df.iloc[:, 0]

# Drop unnecessary columns that are not required for further analysis
df2 = df.drop(columns=["Unnamed: 0", "Unnamed: 9", "Unnamed: 10", "Unnamed: 11"], axis=1)

# Define new column names for the remaining columns.
# These names correspond to the measurements in the dataset.
rename_columns = [
    "Mean Daily Flow - Cumecs", "Mean Daily Flow - Cumecs", "Mean Daily Flow - Cumecs", "Mean Daily Flow - Cumecs", 
    "Daily Rainfall Total - mm", "Daily Rainfall Total - mm", "Daily Rainfall Total - mm", "Daily Rainfall Total - mm"
]
df2.columns = rename_columns 

# Use the first row to extract station names and create a multi-index for the columns.
# Each column will have a two-level index: the measurement type and the corresponding station.
row2 = df2.iloc[0] 
column_tuples = list(zip(rename_columns, row2))  
multi_index = pd.MultiIndex.from_tuples(column_tuples, names=["Measure", "Station"])
df2.columns = multi_index 

# Insert the 'Date' column back into the DataFrame and remove the first row, 
# since it was used to create the multi-index and is no longer needed.
df2.insert(0, "Date", data_series)  
df2.drop(index=0, axis=0, inplace=True)  

# Create a working copy and convert data types:
# Copy the DataFrame, then convert all columns (except 'Date') to numeric values.
df = df2.copy()
df = df2.iloc[:, 1:].apply(pd.to_numeric, errors='coerce')  # Convert measurement columns to numeric, setting errors to NaN`1
df.insert(0, "Date", data_series)  # Reinsert the Date column as the first column

# Generate LaTeX code for a preview of the table 
table_latex = df.head().to_latex(index=True)


```

```{python, echo=FALSE, results='asis'}
table_str = "\\resizebox{\\textwidth}{!}{\n" + table_latex + "\n}"
print(table_str)
```

## Data Cleaning

After reformatting the data, the next step was to clean it. The first part of the cleaning process involved visualizing the data to understand its distribution, identify any outliers, and determine how best to proceed with further cleaning.

```{python, echo=FALSE}
ax = df.iloc[:, 1:].plot(kind="box", figsize=(50, 6))
ax.set_title("Boxplot of Original Data", fontsize=20)
print("Following are the minimum values:\n")
print(df['Mean Daily Flow - Cumecs'].min())
print(df['Daily Rainfall Total - mm'].min(), "\n")
print("Following are the Maximum values:\n")
print(df['Mean Daily Flow - Cumecs'].max())
print(df['Daily Rainfall Total - mm'].max(), "\n")
```
Upon visual inspection and analysis of the minimum and maximum values within the multi-indexed dataset, it became evident that several extreme values were present—both unusually negative and excessively large. For instance, the Mean Daily Flow includes implausible minimum values such as -999.0 at stations like Crakehill and Skip Bridge, while the Daily Rainfall Total records similarly invalid negative readings. On the upper end, extreme maximum values were observed, including rainfall totals exceeding 80,000 mm at Malham Tarn and over 5,000 mm at Arkengarthdale.

Given the context of this dataset—where values represent physical quantities such as Mean Daily Flow (cumecs) and Daily Rainfall Total (mm) such extremes are unrealistic. Negative values are physically impossible, and enormous values suggest data entry errors, sensor malfunctions, or legacy anomalies.

An initial consideration was to remove all negative values and apply outlier filtering. However, this approach would compromise the time series continuity required for downstream forecasting tasks—mainly when predicting future values such as Skelton’s Mean Daily Flow. Removing data points could lead to inconsistent timestamps and weaken the model’s ability to learn from temporal patterns.

To address this, we decided to apply winsorization to the dataset. Winsorization limits extreme values to a defined percentile range (in this case, the 1st and 99th percentiles), allowing us to retain all timestamps while minimizing the influence of outliers. This process preserves the structural goodness of the time series and ensures the model trains on realistic and temporally consistent data.
```{python, tidy=TRUE, tidy.opts=list(width.cutoff=60)}

# Apply winsorization to all columns in the dataframe to cap extreme values 
# The the top and bottom 1% while preserving the structure of the data
df_winsorized = df.apply(lambda df: winsorize(df, limits=[0.01, 0.01]))

# Create a complete date range from the earliest to the latest date in the dataset
date_range = pd.date_range(start=df_winsorized["Date"].min(), end=df_winsorized["Date"].max(), freq="D")

# Check how many dates are missing from the dataset compared to the complete date range
missing_dates = len(date_range.difference(df_winsorized["Date"]))
print("Missing dates:", missing_dates)
```
```{python, echo=FALSE}
ax = df_winsorized.iloc[:, 1:].plot(kind="box", figsize=(50, 6))
ax.set_title("Boxplot of Winsorized Features", fontsize=20)

# Print min values of selected columns
print("Following are the minimum values of Winsorized Dataframe:\n")
print("Mean Daily Flow - Cumecs:", df_winsorized['Mean Daily Flow - Cumecs'].min())
print("Daily Rainfall Total - mm:", df_winsorized['Daily Rainfall Total - mm'].min(), "\n")

# Print max values of selected columns
print("Following are the maximum values of Winsorized Dataframe:\n")
print("Mean Daily Flow - Cumecs:", df_winsorized['Mean Daily Flow - Cumecs'].max())
print("Daily Rainfall Total - mm:", df_winsorized['Daily Rainfall Total - mm'].max(), "\n")


df_time = df_winsorized.copy()
df_time.set_index("Date", inplace=True)
```


With the data cleaned and winsorized to reduce the influence of extreme values, the next step was to explore the dataset for potential predictive relationships. The first approach involved visualizing the time series data to assess whether there were any apparent patterns or correlations between variables over time.

The time series plot below presents each feature as a separate subplot, sharing the same timeline. This visualization provides an intuitive overview of the data’s temporal behavior. It helps reveal whether certain variables may move in tandem, which is an important first step in identifying strong predictors.

In addition, a summary statistics table was generated to complement the visual analysis. This table includes key descriptive metrics such as the mean, standard deviation, and range for each feature, offering a clearer understanding of the overall scale and variability in the dataset.

```{python}

# Plot all time series columns as individual subplots, sharing the same x-axis (date)
# This helps visually compare trends and detect potential relationships across variables
df_time.plot(figsize=(50, 8), subplots=True, sharex=True)

# Generate summary statistics (count, mean, std, min, quartiles, max) 
# for each variable
# Useful for understanding the distribution and scale of each time series feature
summary_stats = df_time.describe()
```
```{python, echo=FALSE, results='asis'}
table_str = "\\resizebox{\\textwidth}{!}{\n" + summary_stats.to_latex(index=True) + "\n}"
print(table_str)
```

While the summary statistics provided a general understanding of the data's distribution, they offered limited insight into the relationships between variables. To address the limited insight, a correlation matrix was generated to evaluate how strongly the features are related, particularly regarding their potential predictive value for forecasting Skelton's Mean Daily Flow.


```{python}
corr_time = df_time.corr()

```
```{python, echo=FALSE, results='asis'}

summary_str = corr_time.to_latex(index=True)

table_str = "\\resizebox{\\textwidth}{!}{\n" + corr_time.to_latex(index=True) + "\n}"
print(table_str)
```

The correlation matrix shows that the flow measurements at stations like Crakehill, Skip Bridge, and Westwick are all highly correlated with Skelton's flow (with correlation coefficients of 0.97, 0.94, and 0.91, respectively). This suggests that these stations are likely to be valuable predictors.

In contrast, while still somewhat correlated, rainfall measurements show weaker relationships. Notably, 'Daily Rainfall Total - mm' at East Cowton had the lowest correlation with Skelton's flow (0.18), indicating minimal predictive value. As a result, this feature was removed from the dataset to reduce dimensionsa and potential noise, allowing the model to focus on more relevant signals.

```{python}
df_time2 = df_time.drop(columns=[('Daily Rainfall Total - mm', 'East Cowton')])
```
```{python, echo=FALSE, results='asis'}

table_str = "\\resizebox{\\textwidth}{!}{\n" + df_time2.head().to_latex(index=True) + "\n}"
print(table_str)
```

With the data cleaned and redundant features removed, the final step was to address the issue of inconsistent units within the dataset. As observed in the multi-indexed structure, the dataset contains two types of measurements: 'Cumecs' for flow rates and 'mm' for rainfall totals.

This discrepancy poses a challenge when incorporating both measurements into a unified model, mainly when predicting Skelton's Mean Daily Flow. To ensure all features contribute proportionally and to avoid scale dominance by any variable, min-max normalization was applied.

Min-max scaling transforms all values to a standard range—typically between 0 and 1—which is appropriate since the dataset contains only non-negative values. This transformation preserves the relationships between values while aligning them consistently, allowing the model to interpret the features more effectively.

```{python}
target_col = ('Mean Daily Flow - Cumecs', 'Skelton')
feature_cols = df_time2.columns.difference([target_col])

# Fit a scaler for the input features only
X_scaler = MinMaxScaler(feature_range=(0, 1))
X_scaled = X_scaler.fit_transform(df_time2[feature_cols])
df_X_scaled = pd.DataFrame(X_scaled, columns=feature_cols, index=df_time2.index)

# Fit a scaler for the target variable only
y_scaler = MinMaxScaler(feature_range=(0, 1))
y_scaled = y_scaler.fit_transform(df_time2[[target_col]])
df_y_scaled = pd.DataFrame(y_scaled, columns=[target_col], index=df_time2.index)

# Now you can construct your training data:
X = df_X_scaled.values   
y = df_y_scaled.values  

y = y.reshape(-1, 1)

```

```{python, echo=FALSE, results='asis'}
scaler = MinMaxScaler(feature_range=(0,1)).fit(df_time2)
df_scaled = pd.DataFrame(scaler.fit_transform(df_time2), columns=df_time2.columns, index=df_time2.index)

table_str = "\\resizebox{\\textwidth}{!}{\n" + df_scaled.head().to_latex(index=True) + "\n}"
print(table_str, "\n")
```
```{python, echo=FALSE}
# Print min values of selected columns
print("Following are the minimum values of Nomalized Data:\n")
print("Mean Daily Flow - Cumecs:", df_scaled['Mean Daily Flow - Cumecs'].min(), "\n")
print("Daily Rainfall Total - mm:", df_scaled['Daily Rainfall Total - mm'].min(), "\n")
print("\n")
# Print max values of selected columns
print("Following are the maximum values of Normalized Data:\n")
print("Mean Daily Flow - Cumecs:", df_scaled['Mean Daily Flow - Cumecs'].max(),"\n")
print("Daily Rainfall Total - mm:", df_scaled['Daily Rainfall Total - mm'].max(), "\n")
```


# Implementation of MLP Program

With the data cleaned and redundant features removed, the next step was to build a neural network to model and predict Skelton’s Mean Daily Flow. The network was implemented in Python using NumPy, providing complete control over the architecture and training process. The implementation centers around a NeuralNetwork class that follows the backpropagation algorithm supports multiple hidden layers, customizable activation functions (including sigmoid, ReLU, and tanh), and uses Xavier initialization for stable weight scaling. The class includes methods for forward propagation, which computes layer-wise activations; backward propagation, which calculates gradients and updates the weights using stochastic gradient descent; and training, where the model iteratively improves over several epochs using mini-batch updates. Additionally, it includes a prediction method that feeds new input through the trained network to generate outputs. Throughout training, the model tracks and visualizes the loss over time, allowing for intuitive convergence monitoring. 

In addition to enhance the performance and stability of the neural network during training, an additional Optimizer class was implemented to incorporate several standard optimization techniques. This class builds on the MLP structure and supports four key improvements: momentum, weight decay, learning rate annealing, and the Bold Driver heuristic. Momentum helps smooth out updates by incorporating a fraction of the previous gradient, accelerating convergence, and reducing oscillations. Weight decay introduces regularization, encouraging smaller weights and helping to prevent overfitting. Learning rate annealing allows the step size to decrease gradually over epochs, supporting finer adjustments as training progresses. The Bold Driver mechanism dynamically adjusts the learning rate based on the direction of the loss: if the loss worsens, the learning rate is reduced; if the loss improves, it is slightly increased. This adaptive behavior enables more responsive learning without requiring manual tuning during training. Together, these enhancements aim to make the optimization process more robust and efficient, mainly when training deeper networks or working with noisy data.


```{python, echo = TRUE, results = 'hide'}

class NeuralNetwork:
    
    def __init__(self, input_size, hidden_sizes, output_size, activation="sigmoid", learning_rate=0.01,
                 momentum=0.0, weight_decay=0.0, annealing_rate=1.0, bold_driver_enabled=False,
                 increase_factor=1.01, decrease_factor=0.99):
        self.input_size = input_size
        self.hidden_sizes = hidden_sizes
        self.output_size = output_size
        self.learning_rate = learning_rate
        self.activation_name = activation
        

        # Define activation functions
        self.activation = self.get_activation_function(activation)
        self.activation_deriv = self.get_activation_derivative(activation)

        # Define layers
        self.layers = [input_size] + hidden_sizes + [output_size]
        
        # Weight initialization (Xavier Initialization)
        self.weights = [np.random.randn(self.layers[i], self.layers[i+1]) * np.sqrt(1 / self.layers[i]) 
                        for i in range(len(self.layers) - 1)]

        # Initialize the optimizer with the provided parameters
        self.optimizer = Optimizer(self, learning_rate, momentum, weight_decay, annealing_rate,
                                   bold_driver_enabled, increase_factor, decrease_factor)

    def get_activation_function(self, name):
        """Return the activation function corresponding to the name."""
        if name == "sigmoid":
            return lambda x: 1 / (1 + np.exp(-x))
        elif name == "relu":
            return lambda x: np.maximum(0, x)
        elif name == "tanh":
            return lambda x: np.tanh(x)
        else:
            print("Not a valid activation function")
            return None

    def get_activation_derivative(self, name):
        """Return the derivative of the activation function."""
        if name == "sigmoid":
            return lambda x: x * (1 - x) 
        elif name == "relu":
            return lambda x: (x > 0).astype(float)
        elif name == "tanh":
            return lambda x: 1 - x**2
        else:
            print("Not a valid activation function")
            return None
    
    def feedforward(self, X):
        """Perform forward propagation through the network."""
        self.a_values = [X]
        self.z_values = []
        
        for i in range(len(self.weights)):
            z = np.dot(self.a_values[-1], self.weights[i])  
            self.z_values.append(z)
            
            if i < len(self.weights) - 1:
                activation = self.activation(z)  
            else:
                if self.activation_name == "sigmoid": 
                    activation = 1 / (1 + np.exp(-np.clip(z, -500, 500)))  
                else:  
                    activation = z  
                
            self.a_values.append(activation)
        
        return self.a_values[-1]  # Return output layer activation

    def backward(self, X, y, batch_size):
        """Perform backpropagation and update weights using the optimizer."""
        output = self.a_values[-1]
        deltas = [y - output]  # Compute error at output layer
    
        # Backpropagate through hidden layers
        for i in range(len(self.weights) - 1, 0, -1):
            delta = deltas[-1].dot(self.weights[i].T) * self.activation_deriv(self.a_values[i])
            deltas.append(delta)
    
        deltas.reverse()
    
        # Compute gradients for all layers
        gradients = []
        for i in range(len(self.weights)):
            # Compute gradient and average over the mini-batch
            grad = -self.a_values[i].T.dot(deltas[i]) / batch_size  
            gradients.append(grad)
    
        # Update weights using the optimizer
        self.optimizer.update(gradients)

    def train(self, X, y, epochs=1000, batch_size=1):
        """Train the network using mini-batch SGD and record the loss."""
        self.loss_history = []
        n_samples = X.shape[0]
        
        for epoch in range(epochs):
            # Shuffle the dataset at the beginning of each epoch
            indices = np.arange(n_samples)
            np.random.shuffle(indices)
            X_shuffled = X[indices]
            y_shuffled = y[indices]
            
            epoch_loss = 0
            n_batches = 0
            
            # Process mini-batches
            for start in range(0, n_samples, batch_size):
                end = start + batch_size
                X_batch = X_shuffled[start:end]
                y_batch = y_shuffled[start:end]
                
                output = self.feedforward(X_batch)
                loss = np.mean((y_batch - output) ** 2)
                epoch_loss += loss
                n_batches += 1
            
                self.backward(X_batch, y_batch, batch_size)
            
            # Record average loss for this epoch
            avg_epoch_loss = epoch_loss / n_batches
            self.loss_history.append(avg_epoch_loss)

            # Adjust learning rate using Bold Driver or annealing
            self.optimizer.adjust_learning_rate(avg_epoch_loss)
            
            if epoch % 100 == 0:
                print(f"Epoch {epoch}: Loss = {avg_epoch_loss}")
        
        # Plot training loss over epochs
        plt.plot(range(epochs), self.loss_history)
        plt.xlabel("Epochs")
        plt.ylabel("Loss")
        plt.title("Training Loss Over Time")
        plt.show()
    
    def score(self, X, y):
        """Compute the R² score for the model's predictions on X compared to y."""
        predictions = self.predict(X).flatten()
        y_true = y.flatten()
        ss_res = np.sum((y_true - predictions) ** 2)
        ss_tot = np.sum((y_true - np.mean(y_true)) ** 2)
        return 1 - ss_res / ss_tot

    def predict(self, X):
        """Generate predictions for the input data."""
        return self.feedforward(X)

class Optimizer:
    def __init__(self, network, learning_rate=0.01, momentum=0.0, weight_decay=0.0,
                 annealing_rate=1.0, bold_driver_enabled=False, increase_factor=1.01, decrease_factor=0.99):
        # Initialize the optimizer with various techniques to improve training.
        self.network = network
        self.learning_rate = learning_rate
        self.base_learning_rate = learning_rate 
        self.momentum = momentum
        self.weight_decay = weight_decay
        self.annealing_rate = annealing_rate  
        self.bold_driver_enabled = bold_driver_enabled
        self.increase_factor = increase_factor
        self.decrease_factor = decrease_factor
        self.epoch = 0
        self.prev_loss = None  

        # Initialize momentum velocities for each weight matrix.
        self.velocities = [np.zeros_like(w) for w in self.network.weights]

    def update(self, gradients):
        """Update the network's weights using momentum, weight decay, and the computed gradients."""
        for i in range(len(self.network.weights)):
            decay_term = self.weight_decay * self.network.weights[i]
            self.velocities[i] = self.momentum * self.velocities[i] - self.learning_rate * (gradients[i] + decay_term)
            self.network.weights[i] += self.velocities[i]

    def adjust_learning_rate(self, current_loss):
        """
        Adjust the learning rate after each epoch using:
         - Bold Driver: slightly adjust the learning rate based on loss improvement.
         - Annealing: gradually decay the learning rate.
        """
        if self.bold_driver_enabled:
            if self.prev_loss is not None:
                if current_loss > self.prev_loss:
                    self.learning_rate *= self.decrease_factor
                else:
                    self.learning_rate *= self.increase_factor
            self.prev_loss = current_loss  

        if self.annealing_rate != 1.0:
            self.epoch += 1
            self.learning_rate *= self.annealing_rate


```
```{python, echo=FALSE}


class NeuralNetwork:
    
    def __init__(self, input_size, hidden_sizes, output_size, activation="sigmoid", learning_rate=0.01,
                 momentum=0.0, weight_decay=0.0, annealing_rate=1.0, bold_driver_enabled=False,
                 increase_factor=1.01, decrease_factor=0.99):
        self.input_size = input_size
        self.hidden_sizes = hidden_sizes
        self.output_size = output_size
        self.learning_rate = learning_rate
        self.activation_name = activation
        

        # Define activation functions
        self.activation = self.get_activation_function(activation)
        self.activation_deriv = self.get_activation_derivative(activation)

        # Define layers
        self.layers = [input_size] + hidden_sizes + [output_size]
        
        # Weight initialization (Xavier Initialization)
        self.weights = [np.random.randn(self.layers[i], self.layers[i+1]) * np.sqrt(1 / self.layers[i]) 
                        for i in range(len(self.layers) - 1)]

        # Initialize the optimizer with the provided parameters
        self.optimizer = Optimizer(self, learning_rate, momentum, weight_decay, annealing_rate,
                                   bold_driver_enabled, increase_factor, decrease_factor)

    def get_activation_function(self, name):
        """Return the activation function corresponding to the name."""
        if name == "sigmoid":
            return lambda x: 1 / (1 + np.exp(-x))
        elif name == "relu":
            return lambda x: np.maximum(0, x)
        elif name == "tanh":
            return lambda x: np.tanh(x)
        else:
            print("Not a valid activation function")
            return None

    def get_activation_derivative(self, name):
        """Return the derivative of the activation function."""
        if name == "sigmoid":
            return lambda x: x * (1 - x) 
        elif name == "relu":
            return lambda x: (x > 0).astype(float)
        elif name == "tanh":
            return lambda x: 1 - x**2
        else:
            print("Not a valid activation function")
            return None
    
    def feedforward(self, X):
        """Perform forward propagation through the network."""
        self.a_values = [X]
        self.z_values = []
        
        for i in range(len(self.weights)):
            z = np.dot(self.a_values[-1], self.weights[i])  
            self.z_values.append(z)
            
            if i < len(self.weights) - 1:
                activation = self.activation(z)  
            else:
                if self.activation_name == "sigmoid": 
                    activation = 1 / (1 + np.exp(-np.clip(z, -500, 500)))  
                else:  
                    activation = z  
                
            self.a_values.append(activation)
        
        return self.a_values[-1]  # Return output layer activation

    def backward(self, X, y, batch_size):
        """Perform backpropagation and update weights using the optimizer."""
        output = self.a_values[-1]
        deltas = [y - output]  # Compute error at output layer
    
        # Backpropagate through hidden layers
        for i in range(len(self.weights) - 1, 0, -1):
            delta = deltas[-1].dot(self.weights[i].T) * self.activation_deriv(self.a_values[i])
            deltas.append(delta)
    
        deltas.reverse()
    
        # Compute gradients for all layers
        gradients = []
        for i in range(len(self.weights)):
            # Compute gradient and average over the mini-batch
            grad = -self.a_values[i].T.dot(deltas[i]) / batch_size  
            gradients.append(grad)
    
        # Update weights using the optimizer
        self.optimizer.update(gradients)

    def train(self, X, y, epochs=1000, batch_size=1):
        """Train the network using mini-batch SGD and record the loss."""
        self.loss_history = []
        n_samples = X.shape[0]
        
        for epoch in range(epochs):
            # Shuffle the dataset at the beginning of each epoch
            indices = np.arange(n_samples)
            np.random.shuffle(indices)
            X_shuffled = X[indices]
            y_shuffled = y[indices]
            
            epoch_loss = 0
            n_batches = 0
            
            # Process mini-batches
            for start in range(0, n_samples, batch_size):
                end = start + batch_size
                X_batch = X_shuffled[start:end]
                y_batch = y_shuffled[start:end]
                
                output = self.feedforward(X_batch)
                loss = np.mean((y_batch - output) ** 2)
                epoch_loss += loss
                n_batches += 1
            
                self.backward(X_batch, y_batch, batch_size)
            
            # Record average loss for this epoch
            avg_epoch_loss = epoch_loss / n_batches
            self.loss_history.append(avg_epoch_loss)

            # Adjust learning rate using Bold Driver or annealing
            self.optimizer.adjust_learning_rate(avg_epoch_loss)
        

    
    def score(self, X, y):
        """Compute the R² score for the model's predictions on X compared to y."""
        predictions = self.predict(X).flatten()
        y_true = y.flatten()
        ss_res = np.sum((y_true - predictions) ** 2)
        ss_tot = np.sum((y_true - np.mean(y_true)) ** 2)
        return 1 - ss_res / ss_tot

    def predict(self, X):
        """Generate predictions for the input data."""
        return self.feedforward(X)

class Optimizer:
    def __init__(self, network, learning_rate=0.01, momentum=0.0, weight_decay=0.0,
                 annealing_rate=1.0, bold_driver_enabled=False, increase_factor=1.01, decrease_factor=0.99):
        # Initialize the optimizer with various techniques to improve training.
        self.network = network
        self.learning_rate = learning_rate
        self.base_learning_rate = learning_rate 
        self.momentum = momentum
        self.weight_decay = weight_decay
        self.annealing_rate = annealing_rate  
        self.bold_driver_enabled = bold_driver_enabled
        self.increase_factor = increase_factor
        self.decrease_factor = decrease_factor
        self.epoch = 0
        self.prev_loss = None  

        # Initialize momentum velocities for each weight matrix.
        self.velocities = [np.zeros_like(w) for w in self.network.weights]

    def update(self, gradients):
        """Update the network's weights using momentum, weight decay, and the computed gradients."""
        for i in range(len(self.network.weights)):
            decay_term = self.weight_decay * self.network.weights[i]
            self.velocities[i] = self.momentum * self.velocities[i] - self.learning_rate * (gradients[i] + decay_term)
            self.network.weights[i] += self.velocities[i]

    def adjust_learning_rate(self, current_loss):
        """
        Adjust the learning rate after each epoch using:
         - Bold Driver: slightly adjust the learning rate based on loss improvement.
         - Annealing: gradually decay the learning rate.
        """
        if self.bold_driver_enabled:
            if self.prev_loss is not None:
                if current_loss > self.prev_loss:
                    self.learning_rate *= self.decrease_factor
                else:
                    self.learning_rate *= self.increase_factor
            self.prev_loss = current_loss  

        if self.annealing_rate != 1.0:
            self.epoch += 1
            self.learning_rate *= self.annealing_rate
```
  
# Training and Network Selection

During training and network selection for the MLP, I had to balance model complexity with the ability to generalize from a relatively small dataset of 1,461 samples, which made overfitting a significant concern. To address this, I incorporated techniques such as weight decay, momentum, and learning rate annealing to help regularize the model and ensure stable convergence during training. I limited the network to three hidden layers because a more complex architecture could easily overfit the data, and my experiments showed that one to three hidden layers were sufficient to capture the essential patterns while keeping the model simple and efficient.

```{python, echo=FALSE}
np.random.seed(42)
random.seed(42)
```

```{python, echo =TRUE, results = 'hide'}

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
optimized_architectures = [
    [4], [8], [16], [4, 4], [8, 4], [16, 8],
    [8, 8], [16, 16], [20, 16, 8], [16, 4],
    [16, 8, 4], [12, 6, 4], [15, 12, 6, 4]
]

optimized_results = {}
best_optimized_loss = float('inf')
best_optimized_arch = None
best_model = None

# Loop over architectures, train each model, and record its validation loss and training time
# Loop over architectures, train each model, and record its validation loss and training time
for arch in optimized_architectures:
    model = NeuralNetwork(input_size=6, hidden_sizes=arch, output_size=1, activation="sigmoid",
                          learning_rate=0.5, momentum=0.9, weight_decay=0.0001, annealing_rate=0.999,
                          bold_driver_enabled=False)
    start_time = time.time()
    model.train(X_train, y_train, epochs=2000, batch_size=20)
    training_time = time.time() - start_time
    
    # Compute validation loss inline
    val_loss = ((y_test - model.predict(X_test)) ** 2).mean()
    optimized_results[str(arch)] = (val_loss, training_time)
    
    if val_loss < best_optimized_loss:
        best_optimized_loss = val_loss
        best_optimized_arch = arch
        best_model = model
```

```{python, echo =TRUE, results = 'hide'}
# Train a baseline model (no optimizations)
baseline_model = NeuralNetwork(
    input_size=6, 
    hidden_sizes= best_optimized_arch ,   # predefined architecture
    output_size=1, 
    activation="sigmoid",
    learning_rate=0.5, 
    momentum=0.0, 
    weight_decay=0.0, 
    annealing_rate=1.0,
    bold_driver_enabled=False
)
baseline_model.train(X_train, y_train, epochs=2000, batch_size=20)
baseline_train_score = baseline_model.score(X_train, y_train)
baseline_val_score = baseline_model.score(X_test, y_test)
baseline_val_loss = ((y_test - baseline_model.predict(X_test)) ** 2).mean()
best_model_val_loss = ((y_test - best_model.predict(X_test)) ** 2).mean()


```
```{python, echo=FALSE, results='show'}
        
print(f"Best optimized arch: {best_optimized_arch} with Val Loss: {best_optimized_loss:.4f}","\n")

print(f"Baseline Model - Val Loss: {baseline_val_loss:.4f}", "\n")
print(f"Optimized Model - Val Loss: {best_model_val_loss:.4f}", "\n")

# Plot loss curves for both models
plt.figure(figsize=(10, 6))
plt.plot(best_model.loss_history, label='Optimized Model Loss')
plt.plot(baseline_model.loss_history, label='Baseline Model Loss')
plt.xlabel("Epochs")
plt.ylabel("Loss (MSE)")
plt.title("Training Loss Comparison")
plt.legend()
plt.show()


```

```{python, echo=FALSE}
# Scatter plot: Optimized model predictions vs. true values
preds_opt = best_model.predict(X_test).flatten()
y_true = y_test.flatten()
corr_coef_opt = np.corrcoef(y_true, preds_opt)[0, 1]
plt.figure(figsize=(6, 6))
plt.scatter(y_true, preds_opt, alpha=0.5)
plt.xlabel("True Values")
plt.ylabel("Predicted Values")
plt.title(f"Optimized Model\nPearson Corr: {corr_coef_opt:.4f}")
plt.plot([y_true.min(), y_true.max()], [y_true.min(), y_true.max()], 'r--')
plt.show()
```

```{python, echo=FALSE}
# Scatter plot: Baseline model predictions vs. true values
preds_base = baseline_model.predict(X_test).flatten()
corr_coef_base = np.corrcoef(y_true, preds_base)[0, 1]
plt.figure(figsize=(6, 6))
plt.scatter(y_true, preds_base, alpha=0.5)
plt.xlabel("True Values")
plt.ylabel("Predicted Values")
plt.title(f"Baseline Model\nPearson Corr: {corr_coef_base:.4f}")
plt.plot([y_true.min(), y_true.max()], [y_true.min(), y_true.max()], 'r--')
plt.show()
```


After testing multiple architectures, the configuration with hidden layers [16, 8, 4] best balanced complexity and generalization. This optimized model achieved a validation loss of 0.0013, with a training R² of 0.9649 and a validation R² of 0.9611. For comparison, I also trained a baseline model with a simpler architecture ([8, 6]) that did not include the optimizer enhancements. The baseline model reached a training R² of 0.9707, a validation R² of 0.9690, and a slightly lower validation loss of 0.0011.

Even though the baseline model's final performance metrics were marginally better, the training loss curves reveal that the optimized model converges much faster. The optimized model escapes local minima more quickly during the early epochs, which is valuable when training time is limited or scaling to more complex tasks.

Overall, the experiment demonstrated that while a simpler model can achieve excellent performance, the advanced optimization techniques incorporated into the [16, 8, 4] architecture can significantly speed up convergence and offer robustness against overfitting. This balance between training efficiency and predictive performance makes the optimized configuration a strong candidate for catchment flow prediction with the available dataset.


# Evaluation of Final Model

After completing the architecture search, the final evaluation focused on comparing two versions of the MLP: the optimized model and the baseline model. The optimized model incorporated advanced training techniques—momentum, weight decay, and learning rate annealing—while the baseline model was built with the same [16, 8, 4] architecture but without these enhancements.

The architecture search identified [16, 8, 4] as the best configuration. With optimizer modifications enabled (momentum of 0.9, weight decay of 0.0001, and an annealing rate of 0.999), the optimized model achieved a validation loss of approximately 0.0013 and demonstrated robust performance with high R² scores. In contrast, the baseline model, trained without optimizer enhancements, recorded a slightly lower validation loss of 0.0011 and marginally higher R² values.

Despite the slight difference in final loss metrics, the training dynamics revealed notable differences. The optimized model converged more rapidly and escaped local minima earlier in the training process, as evidenced by its training loss curve over the 2,000 epochs. This faster convergence is particularly valuable when training time is limited or scaling to larger datasets is necessary.

Scatter plots comparing predicted values to actual outcomes further confirmed that both models generalize well, as shown by high Pearson correlation coefficients. Although the baseline model showed a slight advantage in the final performance, the enhanced convergence behavior of the optimized model suggests that the integration of momentum, weight decay, and learning rate annealing can be beneficial, especially when training dynamics and speed are critical considerations.

In summary, while both models exhibit strong performance with R² scores in the high 90th percentile, the trade-off between the minor edge in final metrics for the baseline model and the faster, more robust convergence of the optimized model provides important insights for selecting the final implementation for catchment flow prediction.

\clearpage
# Works Cited

“Let’s Build a NEURAL NETWORK!” YouTube, YouTube, www.youtube.com/watch?v=gsxGnxfGY7M&t=3918s. Accessed 26 Mar. 2025. 

Mallick, Aadil. “Learn to Build a Neural Network from Scratch-Yes, Really.” Medium, Medium, 17 Feb. 2025, medium.com/@waadlingaadil/learn-to-build-a-neural-network-from-scratch-yes-really-cac4ca457efc. 

“Neural Network From Scratch In Python.” YouTube, YouTube, www.youtube.com/watch?v=MQzG1hfhow4. Accessed 26 Mar. 2025. 
